{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressed Sensing (CS) based ECG compressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: sparsity and compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Sparsity\n",
    "__Theoretical Sparsity__\n",
    "\n",
    "A signal $s \\in \\mathbb{R}^n$ is considered $k$-sparse if it has exactly $k$ non-zero elements, with $k \\ll n$. This means that $n-k$ elements of the signal are exactly zero.\n",
    "$$\n",
    "s = \\begin{pmatrix} s_1 \\\\ s_2 \\\\ \\vdots \\\\ s_n \\end{pmatrix}\n",
    "$$\n",
    "where exactly $k$ elements in $s$ are non-zero, and the remaining $n-k$ elements are zero.\n",
    "\n",
    "\n",
    "__Practical Sparsity__\n",
    "\n",
    "In real-world signals, _exact sparsity is rare_. Instead, signals are often _representable_ (see next section) as __approximately sparse__: only $k$ elements _of the sparse representation_ are significant and carry most of the signal's information, the remaining $n-k$ elements have small, negligible values. \n",
    "\n",
    "The difference lies in the fact that the $n-k$ coefficients are small but not exactly zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Representation of Signals\n",
    "\n",
    "\"Most natural signals, such as images and audio, are highly compressible. This compressibility means that, when the signal is written in an appropriate basis, only a few modes are active, thus reducing the number of values that must be stored for an accurate representation. In other words, a compressible signal $x \\in \\mathbb{R}^n$ may be written as a sparse vector $s \\in \\mathbb{R}^n$ in a transform basis $\\Psi \\in \\mathbb{C}^{n \\times n}$:\n",
    "\n",
    "$$\n",
    "x = \\Psi s.\n",
    "$$\n",
    "\n",
    "If the basis $\\Psi$ is generic, such as the Fourier or wavelet basis, then only the few active terms in $s$ are required to reconstruct the original signal $x$, reducing the data required to store or transmit the signal.\" [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic Transformation-Based Compression\n",
    "\n",
    "A typical transformation-based compression algorithm involves the following steps:\n",
    "\n",
    "1. __Signal capture__: \n",
    "    Fully sense a whole __raw__ signal $x$ and store it. In this project $x$ are the _voltages_ measured by the ECG machine.\n",
    "2. __Transformation to a sparse domain__:\n",
    "    The signal $x$ is transformed to a sparse domain, basically we want to find the sparse vector $s \\in \\mathbb{R}^n$, that contain mostly negligible coefficients.\n",
    "\n",
    "    We exploit $\\Psi \\in \\mathbb{C}^{n \\times n}$ orthogonal basis matrix, also called __dictionary__. Being $\\Psi$ an orthonormal basis, it satisfies $\\Psi^H \\Psi = I$, where $\\Psi^H$ is the Hermitian conjugate (conjugate transpose) of $\\Psi$, and $I$ is the identity matrix. This implies that $\\Psi^{-1} = \\Psi^H$, making the transformation and its inverse straightforward.\n",
    "\n",
    "    Therefore, when $ \\Psi $ is an orthonormal basis, applying $ \\Psi^H $ to the signal effectively inverts the transformation applied by $ \\Psi $, we can use this to obtain sparse representation from original signal:\n",
    "\n",
    "    $$\n",
    "    s = \\Psi^H x\n",
    "    $$\n",
    "\n",
    "    __The use of transforms__:\n",
    "    On a mathematical note: $\\Psi$ is an orthonormal basis composed of functions like Fourier Function, Wavelet, and so on.\n",
    "    The actual computation of $s$ doesn't actually build a dictionary $\\Psi$ to invert and multiplicate to the signal. Instead it directly applies the _transform_ (e.g. FFT, DWT, DCT, ...) to the signal $x$, to immediately obtain _sparse representation_ $s$.\n",
    "\n",
    "3. __Sparsification__: \n",
    "    A fundamental concept is that a threshold is applied to the coefficients, retaining only those that are significant (i.e., above the threshold) and discarding the rest.\n",
    "\n",
    "    A more detailed view reveals that these steps can be performed using a wide range of techniques, depending on the transform employed, and equivalently, on the choice of dictionary.\n",
    "\n",
    "    _This will not be explored as it is not the subject of this project, it's a vast and intresting topic, Brunto&Kutz book in reference provide a good reference to explore more..._\n",
    "\n",
    "4. __Encoding__:\n",
    "    The retained coefficients and their positions are then encoded for storage or transmission. \n",
    "\n",
    "    _Another huge chapter that will not be explored here, again you can refer to the referenced book for more_\n",
    "\n",
    "__Complexity__\n",
    "\n",
    "Such methods can be _extremely_ effective, but they require a _thresholding/sparsification_ step, which introduces non-linearity and computational complexity. \n",
    "\n",
    "In the following is shown that CS-based methods can provide an alternative solution with different advantages...\n",
    "\n",
    "<center>\n",
    "    <img src=\"./.img/MethodsComparison.png\" alt=\"MethodsComparison.png\" width=\"600\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressed Sensing (CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Mathematically, compressed sensing exploits the _sparsity of a signal_ in a __generic basis__ to achieve full signal reconstruction from surprisingly few measurements.\n",
    "\n",
    "If a __signal $x$ is k-sparse in $\\Psi$ (it's a requirement),__ then instead of measuring $x$ directly (n measurements) and then compressing, it is possible to collect dramatically fewer randomly chosen or compressed measurements and then solve for the non-zero elements of s in the transformed coordinate system.\" [2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measurement\n",
    "\n",
    "Instead of acquiring all $n$ samples, a reduced set of $m$ measurements is obtained directly by projecting the signal $x$  onto a measurement matrix $\\Phi$, storing a _compressed measurement_ $y$:\n",
    "\n",
    "$$\n",
    "y = \\Phi x\n",
    "$$\n",
    "\n",
    "\n",
    "where:\n",
    "- $x \\in \\mathbb{R}^n$ _real_ signal coming from sensors\n",
    "- $y \\in \\mathbb{R}^m$ _compressed measurement_\n",
    "- $\\Phi \\in \\mathbb{R}^{m \\times n}$ with $m \\ll n$ is the _measurement matrix_.\n",
    "\n",
    "__Key concept__:\n",
    "\n",
    "In the measurement phase the _sparse representation_ $s$ is __not__ computed, we directly apply the _measurement matrix_ to the _real_ signal $x$. \n",
    "\n",
    "$\\Phi$ does not simply \"select\" $m$ out of $n$ coefficients out of $x$. Instead, $\\Phi$ typically contains random or structured elements that ensure the measurements $y$ retain sufficient information to __later recover__ the sparse signal $s$. \n",
    "\n",
    "Although the _signal $x$ itself is not sparse in the time domain_, __compressed sensing theory exploits the fact that $s$ can be sparsely represented in some transform domain__ (e.g., wavelet or Fourier domain).\n",
    "\n",
    "_Measurement matrix topic is explored some chapters ahead_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery\n",
    "\n",
    "With knowledge of $s \\in \\mathbb{R}^n$ _sparse representation_ of $x$ through $\\Psi$ _dictionary_, it is possible to recovery $x$ itself as previously shown with:\n",
    "$$\n",
    "x = \\Psi s\n",
    "$$\n",
    "\n",
    "Thus the goal of compressed sensing is to find the __sparsest__ vector $s$ that is consistent with:\n",
    "\n",
    "$$\n",
    "y = \\Phi x = \\Phi \\Psi s\n",
    "$$\n",
    "\n",
    "where (again):\n",
    "- $x \\in \\mathbb{R}^n$ _real_ signal coming from sensors\n",
    "- $y \\in \\mathbb{R}^m$ _compressed measurement_\n",
    "- $\\Psi \\in \\mathbb{R}^{n \\times n}$ is the _dictionary_ (same as explained in previous section)\n",
    "- $\\Phi \\in \\mathbb{R}^{m \\times n}$ with $m \\ll n$ is the _measurement matrix_.\n",
    "- $s \\in \\mathbb{R}^n$ is the _sparse representation_ of $x$ in $\\Psi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Non convex problem__\n",
    "\n",
    "\"Such system of equations is __under-determined__ since there are infinitely many consistent solution $s$. The __sparsest solution__ is the one that satisfies:\n",
    "\n",
    "$$\n",
    "\\hat{s} = \\arg_{s} \\min \\|s\\|_0 \\text{ subject to } y = \\Phi \\Psi \\alpha\n",
    "$$\n",
    "\n",
    "where $\\min \\|s\\|_0$ denotes the $\\ell_0$-pseudo-norm, given by the _non-zero entries_, also referred as the _cardinality_ of $s$.\n",
    "\n",
    "The optimization is non-convex, and in general, the solution can only be found with a brute-force search that is combinatorial in $n$ and $K$. In particular, all possible $K$-sparse vectors in $\\mathbb{R}^n$ must be checked; if the exact level of sparsity $K$ is unknown, the search is even broader. Because this search is combinatorial, solving such minimization is intractable for even moderately large $n$ and $K$, and the prospect of solving larger problems does not improve with Mooreâ€™s law of exponentially increasing computational power.\"[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convex equivalent problem__\n",
    "\n",
    "Fortunately, under certain conditions on the measurement matrix $\\Phi$, it is possible to relax the optimization to a convex $\\ell_1$-minimization.\n",
    "\n",
    "$$\n",
    "\\hat{s} = \\arg_{s} \\min \\|s\\|_1 \\text{ subject to } y = \\Phi \\Psi \\alpha\n",
    "$$\n",
    "\n",
    "__In the presence of noise__, the recovery problem is modified to:\n",
    "\n",
    "$$\n",
    "\\hat{s} = \\arg_{s} \\min \\|s\\|_1 \\text{ subject to } \\|y - \\Phi \\Psi s\\|_2 \\leq \\epsilon\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ is a bound on the noise level.\n",
    "\n",
    "There are very specific conditions that must be met for the $\\ell_1$-minimization to converge with high probability to the sparsest solution of $\\ell_0$-minimization. They can be summarized as follows:\n",
    "- __Incoherence__: \n",
    "    A critical concept in compressed sensing is the _incoherence_ between the measurement matrix $\\Phi$ and the dictionary $\\Psi$. Incoherence refers to the property that ensures that the rows of $\\Phi$ are not too similar to the columns of $\\Psi$. This incoherence is vital because it allows the sparse information in the signal $x$ (which is represented in the domain of $\\Psi$) to be evenly spread across the measurements $y$. This spreading ensures that no single measurement in $y$ captures too much or too little information about the signal $x$, which is essential for accurate recovery of the sparse signal $s$ from the measurements $y$.\n",
    "\n",
    "- __Recoverability Condition:__ \n",
    "    A $K$-sparse signal $s \\in \\mathbb{R}^n$ can be properly recovered after Compressive Sensing (CS) if the number of measurements $m$ satisfies:\n",
    "\n",
    "    $$\n",
    "    m \\geq C K \\log\\left(\\frac{n}{K}\\right)\n",
    "    $$\n",
    "\n",
    "    where $C$ is a constant that depends on how __incoherent__ $\\Phi$ and $\\Psi$ are. This condition ensures that enough measurements are taken to accurately recover the sparse signal, accounting for both sparsity and the ambient dimension $n$.\n",
    "\n",
    "    The recoverability condition is a practical guideline that tells you how many measurements $m$ you need to take to ensure that a $k$-sparse signal $s \\in \\mathbb{R}^n$ can be recovered accurately. The $\\log\\left(\\frac{n}{k}\\right)$ term accounts for the dimensionality reduction that occurs when mapping an $n$-dimensional signal into an $m$-dimensional measurement space.\n",
    "\n",
    "\"Roughly speaking, these two conditions guarantee that the matrix $\\Phi |Psi$ acts as a unitary transformation on K-sparse vectors $s$, preserving relative distances between vectors and enabling almost certain signal reconstruction with $\\ell_1$ convex minimization. This is formulated precisely in terms of the restricted isometry property (RIP) that follows.\"[2]\n",
    "\n",
    "- __Restricted Isometry Property (RIP):__\n",
    "    \"The RIP is a property of the matrix $A = \\Phi \\Psi$ that provides a condition under which the matrix will behave well with respect to sparse signals. Specifically, for a matrix $A$ to satisfy the RIP of order $k$ with a constant $\\delta_k$, it must hold that:\n",
    "\n",
    "    $$\n",
    "    (1 - \\delta_k) \\|x\\|_2^2 \\leq \\|A x\\|_2^2 \\leq (1 + \\delta_k) \\|x\\|_2^2\n",
    "    $$\n",
    "\n",
    "    for all $k$-sparse vectors $x$. Here, $\\delta_k$ is the smallest constant such that this inequality holds, and it should be close to zero. This ensures that the matrix $A$ approximately preserves the Euclidean length (and hence the geometry) of all $k$-sparse signals, meaning the measurements are nearly isometric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: main aspects of study and evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspects relevant to the study\n",
    "\n",
    "__Work on signal block__\n",
    "\n",
    "ECG provide continuous data sampling, a record length can vary based on why it is being taken from few minutes, to hours, to days. This work addresses small devices, that will take a number of samples that can vary between 16 and 1024 as __signal block to compress__.\n",
    "\n",
    "__Compression ratio (CR)__\n",
    "\n",
    "\"Important factor for evaluating different methods. CR as follow \n",
    "$$\n",
    "CR(\\%) = 100 \\frac{n - m}{n}\n",
    "$$\n",
    "where $m$ and $n$ are the number of compressed and original samples, respectively. \"[1]\n",
    "\n",
    "__Compression algorithmâ€™s complexity__\n",
    "\n",
    "Very relevant \"when we talk about limited and weak ECG-recorders. The power consumption usually has a linear relation with the complex-ity of systems. Supplying the power for 24-h ambulatory or remote ECG recorders is very important, that encourage \n",
    "us to focus on systems that have low power consumption.\"[1]\n",
    "\n",
    "The focus here is especially on _sampling phase_: one of the goal of the project will be to demonstrate, same as they did in the paper, that a smaller _measurement matrix_ will result in a _more efficient sampling phase_.\n",
    "\n",
    "__Processing speed__\n",
    "\n",
    "\"In emergency situations it will be important. Considering the ambulatory ECG recorders, whatever the data sooner to be presented to a physician, the next orders from a physician can be given sooner as well.\"\n",
    "\n",
    "Here it must be also taken into account the _reconstruction complexity_, in order to provide _usable_ ECG data, it's necessary to be fast both in acquirin and processing the data.\n",
    "\n",
    "_In this work are reproposed the same fundamental metrics and evaluation aspects proposed in the [1] Izadi, V., Shahri, P.K., & Ahani, H. (2020) paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics to Assess the Accuracy of Reconstructed Signal\n",
    "\n",
    "The accuracy of the reconstructed signal in ECG compression algorithms is typically evaluated using two common metrics: the Percentage Root Mean Square Difference (PRD) and Signal-to-Noise Ratio (SNR). These metrics are defined as follows:\n",
    "__Percentage Root Mean Square Difference (PRD)__\n",
    "The PRD is a measure of the difference between the original ECG signal and the reconstructed ECG signal. It is calculated using the following equation:\n",
    "\n",
    "$$\n",
    "\\text{PRD} = 100 \\times \\sqrt{\\frac{\\sum_{i=0}^{N-1} (x(n) - \\hat{x}(n))^2}{\\sum_{i=0}^{N-1} x(n)^2}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $x(n)$ is the original ECG signal.\n",
    "- $\\hat{x}(n)$ is the reconstructed ECG signal.\n",
    "- $N$ is the length of the signal.\n",
    "\n",
    "__Signal-to-Noise Ratio (SNR)__\n",
    "The SNR is another measure used to assess the quality of the reconstructed signal. It is calculated from the PRD using the following equation:\n",
    "\n",
    "$$\n",
    "\\text{SNR} = -20 \\log_{10} \\left(\\frac{\\text{PRD}}{100}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Assessment Based on PRD and SNR\n",
    "\n",
    "Table 1 from the referenced paper classifies the quality of the reconstructed signal based on the PRD and corresponding SNR values:\n",
    "\n",
    "| Quality        | PRD Range      | SNR Range       |\n",
    "|----------------|----------------|-----------------|\n",
    "| Very Good      | 0% < PRD < 2%  | SNR > 33 dB     |\n",
    "| Good           | 2% < PRD < 9%  | 20 dB < SNR < 33 dB |\n",
    "| Undetermined   | PRD â‰¥ 9%       | SNR â‰¤ 20 dB     |\n",
    "\n",
    "This table indicates that when the PRD is less than 2%, the quality of the reconstructed signal can be categorized as \"Very Good.\" For PRD values between 2% and 9%, the quality is considered \"Good,\" and for PRD values above 9%, the quality of the reconstructed signal cannot be precisely determined. __In this study the same metric will be adopted__.\n",
    "\n",
    "_Table based on [1] Izadi, V., Shahri, P.K., & Ahani, H. (2020). A compressed-sensing-based compressor for ECG. *Biomedical Engineering Letters*, 10, 299â€“307. https://doi.org/10.1007/s13534-020-00148-7_\n",
    "\n",
    "_More information on how such measure was established in APPENDIX_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: measurement matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned ant _ECG device_ provide continuous data sampling for consectuive hours, for instance MIT-BIH Arrhythmia Database provides _records_ for each patient for about $30$ consecutive hours, sampled at $360$ $samples/second$. This means that each _record_ has about $650000$ samples.\n",
    "\n",
    "Exploiting _Compressed Sensing_ allows to store only a fraction of such data by immediately computing the _compress measurement_, this work won't delve into the __hardware__ specifics, the [1] Izadi, V., Shahri, P.K., & Ahani, H. (2020) paper provides a possible hardware implementation.\n",
    "\n",
    "What is important to understand in the present study is that on an ECG signal CS-based approach works on _groups of consecutive samples_ within a _record_, each _\"group\"_ is a __signal blocks__.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressing blocks of samples within signal\n",
    "\n",
    "For the whole signal we understood that CS performs:\n",
    "$$\n",
    "y = \\Phi x\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $x \\in \\mathbb{R}^n$ _real_ signal coming from sensors\n",
    "- $y \\in \\mathbb{R}^m$ _compressed measurement_\n",
    "- $\\Phi \\in \\mathbb{R}^{m \\times n}$ with $m \\ll n$ is the _measurement matrix_.\n",
    "\n",
    "In the practical case \"the signal $x$\" becomes the single __signal block__ $y_{block} \\in \\mathbb{R}^d$, where $d$ is the _block size_.\n",
    "\n",
    "$$\n",
    "y_{block} = \\Phi_{p,d} \\cdot x_{block}\n",
    "$$\n",
    "\n",
    "Where $p \\ll d$, $\\Phi_{p,d}$ will reduce $d$ _original samples_ to $p$ samples that compose _compressed measurement_ __for that single block__. \n",
    "\n",
    "__Compressed measurement $y$ of the whole signal is then obtained by simply concatenating previous results__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the measurement matrix is generated\n",
    "\n",
    "In the present work, elements of $\\Phi_{p,d}$ are drawn from a Bernoulli distribution, which is a discrete probability distribution.\n",
    "\n",
    "For each element $\\phi_{ij}$ of the matrix $\\Phi$, a random value is generated that is either $+1$ or $-1$ with equal probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__How to Check that Restricted Isometry Property holds__\n",
    "\n",
    "As previously explained in the theoretical review the Restricted Isometry Property (RIP) is crucial in ensuring that compressed sensing can accurately recover sparse signals from a reduced set of measurements. \n",
    "\n",
    "However checking whether a specific matrix $A$ satisfies the RIP is computationally infeasible for large matrices because it would involve verifying this condition across all possible sparse vectors. \n",
    "\n",
    "Despite this difficulty, generating the measurement matrix $\\Phi$ randomly ensures that $A = \\Phi \\Psi$ is very likely to satisfy the RIP.__*__ This inherent randomness provides a strong theoretical basis for the effectiveness of compressed sensing without the need for direct verification of the RIP.[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: reconstruction of the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries\n",
    "\n",
    "#### _fixed dictionaries_ vs _adaptive dictionary learning_\n",
    "\n",
    "\"\n",
    "Decreasing  the  projection  matrixs  size  will  affect  the order of sparsity. There are two different classes of sparsifying bases: first class is fixed dictionaries such as wavelet transform dictionary or discrete cosine transform (DCT).\n",
    "The second class is adaptive dictionaries that usually present better sparse representation. There are various adaptive dictionary learning algorithms, such as the method of optimal direction  (MOD)  [19],  and  K  singular  value  decomposition (K-SVD) [20] which can present efficient sparsifying dictionary if the training set has been selected accurately. \n",
    "For the case of wearable ECG recorders that are used by a patient, after training a dictionary, the probability of major \n",
    "change in ECG data of patients is low; hence adaptive sparsifying  dictionary  methods  can  be  applied  to  produce  a  more efficient sparsifying dictionary. Since the sparsity has a direct relation with the quality of the reconstructed signal, it leads to compensate for the effect of decreasing the length of the projection matrix. In this work, adaptive dictionary learning is used for the ECG signal, and the result shows that it can be a well alternative to the fixed dictionaries used by previous researches.\"[1]\n",
    "\n",
    "This idea is reproposed in the present work.\n",
    "\n",
    "#### Fixed dictionaries\n",
    "In this work the _DCT_ __fixed dictionaries__ is utilized as a benchmark to test how dictionary learning can improve reconstruction.\n",
    "\n",
    "It's assumed that the reader possesses the necessary knowledge about the topic. This are well known methdos employed in the _signal compression \"world\"_.\n",
    "An overview is provided at the end of the document in the __Appendix__.\n",
    "\n",
    "\n",
    "#### Adaptive Dictionary Learning\n",
    "\n",
    "In this work, two main adaptive dictionary learning algorithms are used: the *Method of Optimal Directions (MOD)* and *K-Singular Value Decomposition (K-SVD)*.\n",
    "\n",
    "The *Method of Optimal Directions (MOD)* is an iterative algorithm where, at each iteration, the goal is to update the dictionary to minimize the reconstruction error given the current sparse coefficients. The dictionary is updated by solving a least-squares problem. This method is particularly efficient when the training set is well-chosen and representative of the signals to be compressed. In this context, MOD generates a dictionary that provides a better sparse representation of the ECG signal, especially when the characteristics of the signal are stable over time, such as in the case of patient-specific ECG data.\n",
    "\n",
    "*K-Singular Value Decomposition (K-SVD)*, on the other hand, is another adaptive dictionary learning technique that builds on the principles of the MOD algorithm but further refines the dictionary update step. In K-SVD, the dictionary atoms are updated one at a time through a singular value decomposition process. This method improves the sparsity of the signal representation by optimizing both the sparse coefficients and the dictionary atoms simultaneously. K-SVD is known for its flexibility and ability to handle complex signals, making it a suitable candidate for ECG signal compression where achieving higher sparsity can significantly improve the reconstruction quality.\n",
    "\n",
    "Both methods allow for the creation of a more tailored dictionary compared to fixed ones, such as DCT, leading to a sparser representation of the ECG data. This sparser representation compensates for the reduction in the size of the measurement matrix, helping to maintain or improve the quality of the reconstructed signal. These adaptive techniques are particularly advantageous in scenarios where the signal remains relatively consistent over time, such as in long-term ECG monitoring, offering a substantial improvement over fixed dictionaries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction method\n",
    "The classic solution in CS is to solve the $\\ell_1$-minimization problem, equivalent to $\\ell_0$-minimization problem. In real cases is always a good idea to considere presence of noise, hence the problem is:\n",
    "$$\n",
    "\\hat{s} = \\arg_{s} \\min \\|s\\|_1 \\text{ subject to } \\|y - \\Phi \\Psi s\\|_2 \\leq \\epsilon\n",
    "$$\n",
    "where $\\epsilon$ is a bound on the noise level.\n",
    "\n",
    "Directly solving the problem __is not convenient in terms of time complexity__, especially because real measurements always present some noise, which needs to be taken into account. \n",
    "\n",
    "#### SL0\n",
    "\n",
    "The *Smoothed â„“0 (SL0)* algorithm offers an efficient alternative to solving the â„“1-minimization problem by approximating the â„“0 norm. The â„“0 norm represents the number of non-zero elements in a vector, which directly captures sparsity, but solving the â„“0-minimization problem is NP-hard. To address this, SL0 approximates the â„“0 norm using a smooth function, which is easier to minimize.\n",
    "\n",
    "The key idea behind SL0 is to use a sequence of smooth functions to approximate the â„“0 norm, starting with a highly smooth (wide) approximation and gradually reducing the smoothness (narrowing the approximation) as the algorithm progresses. This allows the algorithm to efficiently find sparse solutions by iteratively refining the approximation.\n",
    "\n",
    "The SL0 algorithm can be summarized in the following steps:\n",
    "\n",
    "1. **Initialization**: The algorithm starts by choosing an initial estimate for the sparse coefficients, typically based on a least-squares solution.\n",
    "   \n",
    "2. **Smoothing and gradient descent**: A smooth approximation of the â„“0 norm is applied, and a gradient descent method is used to minimize the smooth function. This step leads to a sparsity-promoting solution.\n",
    "   \n",
    "3. **Progressive narrowing**: The smooth function is gradually made less smooth (narrower) over iterations, which more closely approximates the true â„“0 norm. As the smoothing parameter decreases, the solution becomes sparser.\n",
    "\n",
    "4. **Stopping criterion**: The algorithm stops once the approximation is sufficiently narrow or a desired level of sparsity is achieved.\n",
    "\n",
    "SL0 is particularly appealing because it avoids the more computationally expensive â„“1-minimization while still producing sparse solutions. It also directly incorporates noise tolerance by allowing a relaxation of the equality constraint, as in the standard compressed sensing problem:\n",
    "\n",
    "$$\n",
    "\\hat{s} = \\arg_{s} \\min \\|s\\|_0 \\text{ subject to } \\|y - \\Phi \\Psi s\\|_2 \\leq \\epsilon\n",
    "$$\n",
    "\n",
    "Though SL0 approximates the â„“0 norm, it has been shown to perform well in practical applications, often providing faster solutions compared to â„“1-based methods while maintaining accuracy in the presence of noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Direct quotation are enclosed in `\"...\"` and are followed by a reference number inside `[]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Izadi, V., Shahri, P.K., & Ahani, H. (2020). A compressed-sensing-based compressor for ECG. *Biomedical Engineering Letters*, 10, 299â€“307. https://doi.org/10.1007/s13534-020-00148-7\n",
    "\n",
    "[2] __Chapter 3.1 \"Sparsity and Compressed Sensing\" of the Book__:\n",
    "   Brunton, S. L., & Kutz, J. N. (2022). *Data-Driven Science and Engineering: Machine Learning, Dynamical Systems, and Control* (2nd ed.). Cambridge University Press.\n",
    "\n",
    "__Data__:\n",
    "\n",
    "Moody GB, Mark RG. *The impact of the MIT-BIH Arrhythmia Database*. IEEE Eng in Med and Biol 20(3):45-50 (May-June 2001). (PMID: 11446209)\n",
    "\n",
    "Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C., Mark, R., ... & Stanley, H. E. (2000). *PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals*. Circulation [Online]. 101 (23), pp. e215â€“e220.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Cosine Transform (DCT)\n",
    "\n",
    "The Discrete Cosine Transform (DCT) is a transform similar to the Discrete Fourier Transform (DFT) but uses only real numbers and cosines. It is widely used in image and video compression (e.g., JPEG, MPEG) due to its properties that are particularly suitable for these applications.\n",
    "\n",
    "##### Overview of the Discrete Cosine Transform (DCT)\n",
    "\n",
    "The DCT represents a signal as a sum of cosine functions oscillating at different frequencies. It transforms a sequence of real numbers into a sequence of coefficients representing the signal in the frequency domain.\n",
    "\n",
    "#### Types of DCT\n",
    "\n",
    "There are several types of DCT, but the most commonly used are DCT-I, DCT-II, and DCT-III. The most frequently used variant in practical applications is DCT-II, often referred to simply as \"the DCT.\"\n",
    "\n",
    "__DCT-II (The Most Common DCT)__\n",
    "\n",
    "For a sequence of $N$ real numbers $x[n]$, where $n = 0, 1, \\ldots, N-1$, the DCT-II is defined as:\n",
    "\n",
    "$$\n",
    "X[k] = \\sum_{n=0}^{N-1} x[n] \\cos \\left[ \\frac{\\pi}{N} \\left( n + \\frac{1}{2} \\right) k \\right] \\quad \\text{for} \\quad k = 0, 1, \\ldots, N-1\n",
    "$$\n",
    "\n",
    "__Inverse DCT-II__\n",
    "\n",
    "The inverse DCT-II (often referred to as IDCT) is defined as:\n",
    "\n",
    "$$\n",
    "x[n] = \\frac{1}{N} \\left( \\frac{X[0]}{2} + \\sum_{k=1}^{N-1} X[k] \\cos \\left[ \\frac{\\pi}{N} \\left( n + \\frac{1}{2} \\right) k \\right] \\right) \\quad \\text{for} \\quad n = 0, 1, \\ldots, N-1\n",
    "$$\n",
    "\n",
    "__DCT-I__\n",
    "\n",
    "The DCT-I is defined for a sequence $x[n]$ of length $N$ as:\n",
    "\n",
    "$$\n",
    "X[k] = \\sum_{n=0}^{N-1} x[n] \\cos \\left( \\frac{\\pi}{N-1} nk \\right) \\quad \\text{for} \\quad k = 0, 1, \\ldots, N-1\n",
    "$$\n",
    "\n",
    "DCT-I is defined only for sequences of length $N \\geq 2$ and is less commonly used due to boundary conditions.\n",
    "\n",
    "__DCT-III__\n",
    "\n",
    "The DCT-III, often referred to as the inverse DCT of DCT-II, is defined as:\n",
    "\n",
    "$$\n",
    "x[n] = \\frac{1}{2} X[0] + \\sum_{k=1}^{N-1} X[k] \\cos \\left( \\frac{\\pi}{N} k \\left( n + \\frac{1}{2} \\right) \\right) \\quad \\text{for} \\quad n = 0, 1, \\ldots, N-1\n",
    "$$\n",
    "\n",
    "#### Properties of the DCT\n",
    "\n",
    "- __Orthogonality__: The cosine basis functions used in DCT are orthogonal.\n",
    "- __Real-Valued Output__: For real-valued input signals, the DCT output is also real-valued.\n",
    "- __Energy Compaction__: The DCT tends to concentrate the energy of the signal in a few low-frequency components, making it efficient for compression.\n",
    "\n",
    "#### Complexity of DCT\n",
    "\n",
    "__Direct Computation__\n",
    "\n",
    "The direct computation of DCT for a sequence of length $N$ involves $N$ multiplications and $N-1$ additions for each of the $N$ frequency components, resulting in a total complexity of:\n",
    "\n",
    "$$\n",
    "O(N^2)\n",
    "$$\n",
    "\n",
    "__Fast Algorithms for DCT__\n",
    "\n",
    "Fast algorithms, similar to the Fast Fourier Transform (FFT), reduce the computational complexity of the DCT to:\n",
    "\n",
    "$$\n",
    "O(N \\log N)\n",
    "$$\n",
    "\n",
    "These algorithms exploit symmetry properties and use divide-and-conquer approaches to achieve significant computational savings.\n",
    "\n",
    "__Energy Compaction and Low-Frequency Components in DCT__\n",
    "\n",
    "The Discrete Cosine Transform (DCT) has a key property known as energy compaction, where most of the signal's energy is concentrated in a few low-frequency components. This property is essential for efficient compression, as it allows significant data reduction while preserving the essential features of the original signal.\n",
    "\n",
    "In the DCT, the index $k$ represents the frequency component. Low values of $k$ correspond to low-frequency components, which represent slow variations in the signal, while high values of $k$ correspond to high-frequency components, representing rapid variations.\n",
    "\n",
    "__Frequency Interpretation__\n",
    "\n",
    "- $k = 0$: The basis function is a constant, representing the average value of the signal.\n",
    "- Low $k$: Represent slow variations, such as $\\cos \\left( \\frac{\\pi}{N} \\left( n + \\frac{1}{2} \\right) \\cdot 1 \\right)$.\n",
    "- High $k$: Represent rapid variations, such as $\\cos \\left( \\frac{\\pi}{N} \\left( n + \\frac{1}{2} \\right) \\cdot (N-1) \\right)$.\n",
    "\n",
    "__Energy Compaction__\n",
    "\n",
    "The DCT's ability to concentrate energy in low-frequency components means that for many natural signals, including images and audio, most of the significant information can be captured with only a few coefficients. This makes the DCT highly efficient for compression purposes, as the majority of high-frequency coefficients (which represent fine details and noise) can be quantized more coarsely or discarded without significantly affecting the perceived quality of the signal.\n",
    "\n",
    "#### Matrix Representation of the DCT\n",
    "\n",
    "The Discrete Cosine Transform (DCT) can be represented in a matrix form, which is particularly useful for understanding the transform as a linear operation. This approach involves the use of an orthonormal basis matrix formed by cosine functions.\n",
    "\n",
    "__DCT as a Matrix Product__\n",
    "\n",
    "Let $\\mathbf{x}$ be the input signal, which is a column vector of length $N$. The DCT of this signal can be expressed as a matrix-vector multiplication:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\mathbf{\\Psi} \\mathbf{x}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{X}$ is the vector of DCT coefficients, and $\\mathbf{\\Psi}$ is the $N \\times N$ DCT matrix whose elements are defined as:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\Psi}[k,n] = \\cos \\left[ \\frac{\\pi}{N} \\left( n + \\frac{1}{2} \\right) k \\right] \\quad \\text{for} \\quad k, n = 0, 1, \\ldots, N-1\n",
    "$$\n",
    "\n",
    "This matrix $\\mathbf{\\Psi}$ forms an orthonormal basis for the space of real-valued signals of length $N$.\n",
    "\n",
    "__Inverse DCT as a Matrix Product__\n",
    "\n",
    "The inverse DCT (IDCT) can also be represented in matrix form. Given the DCT coefficients $\\mathbf{X}$, the original signal $\\mathbf{x}$ can be recovered as:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\mathbf{\\Psi}^\\top \\mathbf{X}\n",
    "$$\n",
    "\n",
    "Here, $\\mathbf{\\Psi}^\\top$ is the transpose of the DCT matrix $\\mathbf{\\Psi}$, not the conjugate transpose (Hermitian), since the DCT is a real-valued transform and $\\mathbf{\\Psi}$ is a real-valued matrix.\n",
    "\n",
    "__Orthogonality of the DCT Matrix__\n",
    "\n",
    "The matrix $\\mathbf{\\Psi}$ is orthonormal, meaning it satisfies:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\Psi}^\\top \\mathbf{\\Psi} = \\mathbf{I}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{I}$ is the identity matrix. This property ensures that the DCT and IDCT operations are perfect inverses of each other, preserving the energy of the original signal in the frequency domain.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Wavelet Transform (DWT)\n",
    "\n",
    "The Discrete Wavelet Transform (DWT) is a transform used in signal processing and compression, offering advantages over the Discrete Fourier Transform (DFT) and Discrete Cosine Transform (DCT). The DWT provides a time-frequency representation of the signal, capturing both frequency and location information.\n",
    "\n",
    "#### Overview of DWT\n",
    "\n",
    "The DWT decomposes a signal into a set of wavelets, which are localized in both time and frequency. This allows for multi-resolution analysis, where different parts of the signal can be analyzed at different scales.\n",
    "\n",
    "#### Key Concepts\n",
    "\n",
    "- __Wavelets__: Functions that efficiently represent data with sharp changes or edges, localized in time.\n",
    "- __Scaling and Translation__: Wavelets can be scaled (dilated) and translated (shifted) to capture different frequency components and their locations in the signal.\n",
    "- __Multi-Resolution Analysis__: DWT performs analysis at multiple resolutions, capturing both coarse and fine details of the signal.\n",
    "\n",
    "#### DWT Algorithm\n",
    "\n",
    "The DWT of a signal can be computed using recursive filtering and downsampling. The process involves two main steps: decomposition (analysis) and reconstruction (synthesis).\n",
    "\n",
    "__Decomposition (Analysis)__\n",
    "\n",
    "- __Filter Bank__: Apply a pair of filters to the signal: a low-pass filter (L) and a high-pass filter (H). The low-pass filter captures the approximation (low-frequency) components, while the high-pass filter captures the detail (high-frequency) components.\n",
    "- __Downsampling__: After filtering, the signal is downsampled by a factor of 2 (keeping every other sample) to reduce the data size.\n",
    "- __Recursive Decomposition__: The decomposition process is recursively applied to the low-pass filtered signal to create a multi-level decomposition.\n",
    "\n",
    "### Reconstruction (Synthesis)\n",
    "\n",
    "- __Upsampling__: The downsampled components are upsampled by a factor of 2 (inserting zeros between samples).\n",
    "- __Filter Bank__: Apply the synthesis filters (low-pass and high-pass) to the upsampled components.\n",
    "- __Combining__: The filtered components are combined to reconstruct the signal.\n",
    "\n",
    "#### Mathematical Formulation\n",
    "\n",
    "Given a signal $x[n]$:\n",
    "\n",
    "- __Approximation Coefficients (Low Frequency)__:\n",
    "  \n",
    "  $$\n",
    "  A_j[k] = \\sum_n x[n] \\cdot \\phi_{j,k}[n]\n",
    "  $$\n",
    "  \n",
    "  where $\\phi_{j,k}[n]$ are the scaling functions (low-pass).\n",
    "\n",
    "- __Detail Coefficients (High Frequency)__:\n",
    "  \n",
    "  $$\n",
    "  D_j[k] = \\sum_n x[n] \\cdot \\psi_{j,k}[n]\n",
    "  $$\n",
    "  \n",
    "  where $\\psi_{j,k}[n]$ are the wavelet functions (high-pass).\n",
    "\n",
    "#### Advantages of DWT\n",
    "\n",
    "- __Localization__: Wavelets are localized in both time and frequency, allowing DWT to capture transient features more effectively than DFT or DCT.\n",
    "- __Multi-Resolution Analysis__: DWT provides a hierarchical representation, enabling analysis at multiple resolutions and scales.\n",
    "- __Efficient Compression__: DWT often achieves better compression efficiency for images and signals with sharp changes or edges, as it can represent such features more compactly.\n",
    "\n",
    "#### Complexity of DWT\n",
    "\n",
    "__Direct Computation__\n",
    "\n",
    "The direct computation of DWT for a signal of length $N$ involves $O(N)$ operations per level of decomposition. For a full $J$-level decomposition, the total complexity is:\n",
    "\n",
    "$$\n",
    "O(N)\n",
    "$$\n",
    "\n",
    "__Fast Algorithms for DWT__\n",
    "\n",
    "Fast DWT algorithms, such as those based on recursive filtering and downsampling, also achieve a complexity of:\n",
    "\n",
    "$$\n",
    "O(N)\n",
    "$$\n",
    "\n",
    "These algorithms exploit the hierarchical structure of the wavelet transform to achieve efficient computation.\n",
    "\n",
    "__Matrix Representation of the DWT__\n",
    "\n",
    "The Discrete Wavelet Transform (DWT) can also be represented in matrix form, analogous to the matrix representation of the Discrete Cosine Transform (DCT). This approach allows us to see the DWT as a linear operation involving an orthonormal basis formed by wavelet functions.\n",
    "\n",
    "__DWT as a Matrix Product__\n",
    "\n",
    "Let $\\mathbf{x}$ be the input signal, which is a column vector of length $N$. The DWT of this signal can be expressed as a matrix-vector multiplication:\n",
    "\n",
    "$$\n",
    "\\mathbf{W} = \\mathbf{\\Phi} \\mathbf{x}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{W}$ is the vector of wavelet coefficients, and $\\mathbf{\\Phi}$ is the $N \\times N$ wavelet transform matrix. The matrix $\\mathbf{\\Phi}$ is constructed using wavelet functions (for high-frequency components) and scaling functions (for low-frequency components).\n",
    "\n",
    "__Inverse DWT as a Matrix Product__\n",
    "\n",
    "The inverse DWT (IDWT) can be represented in matrix form similarly. Given the wavelet coefficients $\\mathbf{W}$, the original signal $\\mathbf{x}$ can be recovered as:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\mathbf{\\Phi}^\\top \\mathbf{W}\n",
    "$$\n",
    "\n",
    "Here, $\\mathbf{\\Phi}^\\top$ is the transpose of the wavelet transform matrix $\\mathbf{\\Phi}$. Since the DWT is typically real-valued, we use the transpose rather than the conjugate transpose (Hermitian).\n",
    "\n",
    "__Orthogonality of the DWT Matrix__\n",
    "\n",
    "The matrix $\\mathbf{\\Phi}$ is orthonormal, which means it satisfies:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\Phi}^\\top \\mathbf{\\Phi} = \\mathbf{I}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{I}$ is the identity matrix. This property ensures that the DWT and IDWT are perfect inverses of each other, preserving the energy of the original signal while transforming it into the wavelet domain.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Assessment Based on PRD and SNR\n",
    "\n",
    "Table 1 from the referenced paper classifies the quality of the reconstructed signal based on the PRD and corresponding SNR values:\n",
    "\n",
    "| Quality        | PRD Range      | SNR Range       |\n",
    "|----------------|----------------|-----------------|\n",
    "| Very Good      | 0% < PRD < 2%  | SNR > 33 dB     |\n",
    "| Good           | 2% < PRD < 9%  | 20 dB < SNR < 33 dB |\n",
    "| Undetermined   | PRD â‰¥ 9%       | SNR â‰¤ 20 dB     |\n",
    "\n",
    "This table indicates that when the PRD is less than 2%, the quality of the reconstructed signal can be categorized as \"Very Good.\" For PRD values between 2% and 9%, the quality is considered \"Good,\" and for PRD values above 9%, the quality of the reconstructed signal cannot be precisely determined. \n",
    "\n",
    "__Metric Based on Physician Qualitative Assessments__\n",
    "\n",
    "The classification of the PRD and SNR values into \"Very Good,\" \"Good,\" and \"Undetermined\" categories was established based on a study by Zigel et al., which is referenced in the paper. In this study, a link was established between the diagnostic distortion of ECG signals and the PRD metric. The researchers conducted qualitative assessments with physicians, who evaluated the diagnostic quality of reconstructed ECG signals at different PRD levels.\n",
    "\n",
    "The physicians' qualitative assessments provided a subjective but clinically relevant measure of how much distortion could be tolerated in the reconstructed signals before it began to interfere with accurate diagnosis. These evaluations were then correlated with specific PRD values, allowing the researchers to define thresholds where the signal quality was deemed acceptable or unacceptable for clinical use. For instance, a PRD of less than 2% was consistently associated with minimal diagnostic distortion, leading to its classification as \"Very Good.\" As PRD increased, the likelihood of clinically significant distortion also increased, which was reflected in the \"Good\" and \"Undetermined\" categories.\n",
    "\n",
    "This physician-based qualitative assessment was crucial in grounding the PRD and SNR metrics in practical clinical utility, ensuring that the numerical \n",
    "thresholds corresponded to meaningful diagnostic criteria.\n",
    "\n",
    "_Based on [1] Izadi, V., Shahri, P.K., & Ahani, H. (2020). A compressed-sensing-based compressor for ECG. *Biomedical Engineering Letters*, 10, 299â€“307. https://doi.org/10.1007/s13534-020-00148-7_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".namlVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
