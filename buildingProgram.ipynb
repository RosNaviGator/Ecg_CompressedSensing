{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script provides utility functions for formatted printing of NumPy matrices and saving matrices to CSV files.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# system imports\n",
    "import os\n",
    "\n",
    "# third party imports\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def printFormatted(matrix, decimals=4):\n",
    "    \"\"\"\n",
    "    Prints the matrix with formatted elements aligned in columns for improved readability.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    matrix : numpy array\n",
    "        The matrix to be printed.\n",
    "    decimals : int, optional (default=4)\n",
    "        The number of decimal places for formatting the elements.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "        This function does not return any value; it prints the formatted matrix directly to the console.\n",
    "\n",
    "    Notes:\n",
    "    -----\n",
    "    - The function aligns columns based on the maximum width needed for the formatted elements, ensuring the matrix is displayed neatly.\n",
    "    - This function is useful for visual inspection of numerical matrices, especially those with varying magnitudes.\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> matrix = np.array([[1.234567, 123.456789], [0.0001234, 1.2345]])\n",
    "    >>> print('Classic print:')\n",
    "    >>> print(matrix)\n",
    "    Classic print:\n",
    "    [[1.2345670e+00 1.2345679e+02]\n",
    "     [1.2340000e-04 1.2345000e+00]]\n",
    "     \n",
    "    >>> print('\\nFormatted print:')\n",
    "    >>> printFormatted(matrix, decimals=4)\n",
    "         1.2346  123.4568\n",
    "         0.0001    1.2345\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the maximum width needed to keep alignment\n",
    "    max_width = max(len(f'{value:.{decimals}f}') for row in matrix for value in row)\n",
    "\n",
    "    # Create a formatted string for each element in the matrix, ensuring alignment\n",
    "    formatted_matrix = '\\n'.join([' '.join([f'{value:>{max_width}.{decimals}f}' for value in row]) for row in matrix])\n",
    "\n",
    "    # Print the formatted matrix\n",
    "    print(formatted_matrix)\n",
    "\n",
    "\n",
    "def py_test_csv(array):\n",
    "    \"\"\"\n",
    "    Save a numpy array as a CSV file in ./debugCsvPy/py_test.csv\n",
    "\n",
    "    Parameters:\n",
    "    array (numpy.ndarray): The input array to be saved as a CSV file.\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    output_dir = 'debugCsvPy'  # Directory where CSV files will be stored\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    py_dict_path = os.path.join(output_dir, 'py_test.csv')\n",
    "    np.savetxt(py_dict_path, array, delimiter=',', fmt='%.6f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script provides utility functions for generating a Discrete Cosine Transform (DCT) \n",
    "orthonormal basis matrix and for testing various properties of matrices such as independence \n",
    "of columns, normalization, and coherence.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy.fftpack as fftpack\n",
    "import pywt\n",
    "\n",
    "def dct_dictionary(N):\n",
    "    \"\"\"\n",
    "    Generates a Discrete Cosine Transform (DCT) orthonormal basis matrix.\n",
    "\n",
    "    The DCT basis is commonly used in signal processing and data compression. \n",
    "    It transforms a signal into a sum of cosine functions oscillating at different frequencies. \n",
    "    The resulting matrix can be used for orthogonal transformations of signals.\n",
    "    \n",
    "    DCT basis is sparifying.\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The size of the dictionary (i.e., the length of the signal).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict_matrix : numpy.ndarray\n",
    "        The generated DCT dictionary matrix of shape (N, N), where each column represents \n",
    "        a DCT basis vector.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> generate_dct_dictionary(4)\n",
    "    array([[ 0.5       ,  0.5       ,  0.5       ,  0.5       ],\n",
    "           [ 0.65328148,  0.27059805, -0.27059805, -0.65328148],\n",
    "           [ 0.5       , -0.5       , -0.5       ,  0.5       ],\n",
    "           [ 0.27059805, -0.65328148,  0.65328148, -0.27059805]])\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate a DCT basis dictionary\n",
    "    dict_matrix = fftpack.dct(np.eye(N), norm='ortho')    \n",
    "    return dict_matrix\n",
    "\n",
    "\n",
    "\n",
    "## ------------------------------------------------------------------------------------------------\n",
    "## REST OF THE FUNCTIONS ARE FOR TESTING PURPOSES\n",
    "## ------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def compute_independent_columns(A, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Computes the independent columns of a matrix using the QR decomposition.\n",
    "\n",
    "    The function identifies independent columns of a given matrix `A` by performing a QR \n",
    "    decomposition. It selects columns corresponding to non-zero diagonal elements of the \n",
    "    `R` matrix, which are considered linearly independent.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : numpy.ndarray\n",
    "        The matrix for which to compute the independent columns.\n",
    "    tol : float, optional (default=1e-10)\n",
    "        The tolerance value for considering diagonal elements of `R` as non-zero.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ind_cols : numpy.ndarray\n",
    "        A matrix containing the independent columns of `A`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The QR decomposition is used to determine the rank of the matrix `A`.\n",
    "    - Columns corresponding to non-zero diagonal elements of the `R` matrix are considered independent.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "    >>> compute_independent_columns(A)\n",
    "    array([[1, 2],\n",
    "           [4, 5],\n",
    "           [7, 8]])\n",
    "    \"\"\"\n",
    "    # Perform the QR decomposition\n",
    "    Q, R = np.linalg.qr(A)\n",
    "\n",
    "    # Find the independent columns based on the rank of R\n",
    "    rank = np.sum(np.abs(np.diagonal(R)) > tol)\n",
    "    ind_cols = A[:, :rank]\n",
    "\n",
    "    return ind_cols\n",
    "\n",
    "def check_normalization(A):\n",
    "    \"\"\"\n",
    "    Checks if the columns of a matrix are normalized (i.e., each column has a unit norm).\n",
    "\n",
    "    The function calculates the norm of each column in the matrix `A` and checks if all \n",
    "    column norms are close to 1.0, which indicates normalization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : numpy.ndarray\n",
    "        The matrix to check for normalization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    is_normalized : bool\n",
    "        True if all columns of `A` are normalized, False otherwise.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> A = np.array([[1, 0], [0, 1]])\n",
    "    >>> check_normalization(A)\n",
    "    True\n",
    "    \"\"\"\n",
    "    column_norms = np.linalg.norm(A, axis=0)\n",
    "    is_normalized = np.allclose(column_norms, 1.0)\n",
    "    return is_normalized\n",
    "\n",
    "\n",
    "def compute_coherence(matrix):\n",
    "    \"\"\"\n",
    "    Computes the coherence of the given matrix.\n",
    "\n",
    "    Coherence is a measure of the maximum correlation between any two columns of a matrix. \n",
    "    It is useful in various applications, such as signal processing and compressed sensing, \n",
    "    to assess the degree of similarity between different columns of the matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : numpy.ndarray\n",
    "        An N x M matrix where coherence is to be calculated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coherence : float\n",
    "        The coherence of the matrix, defined as the maximum absolute value of the off-diagonal \n",
    "        elements in the Gram matrix of the column-normalized input matrix.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> matrix = np.array([[1, 0], [0, 1]])\n",
    "    >>> compute_coherence(matrix)\n",
    "    0.0\n",
    "    \"\"\"\n",
    "    # Normalize the columns of the matrix\n",
    "    normalized_matrix = matrix / np.linalg.norm(matrix, axis=0, keepdims=True)\n",
    "    \n",
    "    # Compute the Gram matrix (inner products between all pairs of columns)\n",
    "    gram_matrix = np.dot(normalized_matrix.T, normalized_matrix)\n",
    "    \n",
    "    # Remove the diagonal elements (which are all 1's) to only consider distinct columns\n",
    "    np.fill_diagonal(gram_matrix, 0)\n",
    "    \n",
    "    # Compute the coherence as the maximum absolute value of the off-diagonal elements\n",
    "    coherence = np.max(np.abs(gram_matrix))\n",
    "    \n",
    "    return coherence\n",
    "\n",
    "\n",
    "def check_matrix_properties(A):\n",
    "    \"\"\"\n",
    "    Checks various properties of a matrix.\n",
    "\n",
    "    The function checks if the matrix `A` is full rank, if its columns and rows are normalized,\n",
    "    and computes the coherence of the matrix. It also prints the results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : numpy.ndarray\n",
    "        The matrix to check.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> A = np.array([[1, 2], [3, 4]])\n",
    "    >>> check_matrix_properties(A)\n",
    "    \"\"\"\n",
    "    # Check if the matrix is full rank\n",
    "    is_full_rank = np.linalg.matrix_rank(A) == min(A.shape)\n",
    "\n",
    "    # Check if the columns are normalized\n",
    "    is_columns_normalized = check_normalization(A)\n",
    "\n",
    "    # Check if the rows are normalized\n",
    "    is_rows_normalized = check_normalization(A.T)\n",
    "\n",
    "    # Compute the coherence of the matrix\n",
    "    coherence = compute_coherence(A)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Is full rank:\", is_full_rank)\n",
    "    print(\"Are columns normalized:\", is_columns_normalized)\n",
    "    print(\"Are rows normalized:\", is_rows_normalized)\n",
    "    print(\"Coherence:\", coherence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SL0 Algorithm Implementation\n",
    "\n",
    "This file contains an implementation of the Smoothed L0 (SL0) algorithm for sparse signal recovery.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def SL0(y, A, sigma_min, sigma_decrease_factor=0.5, mu_0=2, L=3, A_pinv=None, showProgress=False):\n",
    "    \"\"\"\n",
    "    Returns the sparsest vector `s` that satisfies the underdetermined system of \n",
    "    linear equations `A @ s = y`, using the Smoothed L0 (SL0) algorithm.\n",
    "\n",
    "    Requires:\n",
    "    --------\n",
    "    - numpy as np\n",
    "    \n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    y : numpy array\n",
    "        The observed vector (Mx1), where M is the number of rows in `A`.\n",
    "    \n",
    "    A : numpy array\n",
    "        The measurement matrix (MxN), which should be 'wide', meaning it has more \n",
    "        columns than rows (N > M). The number of rows in `A` must match the length \n",
    "        of `y`.\n",
    "    \n",
    "    sigma_min : float\n",
    "        The minimum value of `sigma`, which determines the stopping criterion for \n",
    "        the algorithm. It should be chosen based on the noise level or desired \n",
    "        accuracy.\n",
    "    \n",
    "    sigma_decrease_factor : float, optional (default=0.5)\n",
    "        The factor by which `sigma` is decreased in each iteration. This should be \n",
    "        a positive value less than 1. Smaller values lead to quicker reduction of \n",
    "        `sigma`, possibly at the cost of accuracy for less sparse signals.\n",
    "    \n",
    "    mu_0 : float, optional (default=2)\n",
    "        The scaling factor for `mu`, where `mu = mu_0 * sigma^2`. This parameter \n",
    "        influences the convergence rate of the algorithm.\n",
    "    \n",
    "    L : int, optional (default=3)\n",
    "        The number of iterations for the inner loop (steepest descent). Increasing \n",
    "        `L` can improve the precision of the result but also increases computational \n",
    "        cost.\n",
    "    \n",
    "    A_pinv : numpy array, optional\n",
    "        The precomputed pseudoinverse of the matrix `A`. If not provided, it will be \n",
    "        calculated within the function as `np.linalg.pinv(A)`. Providing this value \n",
    "        is beneficial if the function is called repeatedly with the same `A`.\n",
    "    \n",
    "    showProgress : bool, optional (default=False)\n",
    "        If `True`, the function prints the current value of `sigma` during each \n",
    "        iteration, which helps monitor the convergence process.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    s : numpy array\n",
    "        The estimated sparse signal (Nx1) that best satisfies the equation `A @ s = y`.\n",
    "\n",
    "    Notes:\n",
    "    -----\n",
    "    - The algorithm works by iteratively reducing `sigma` in a geometric sequence, \n",
    "      starting with `sigma = 2 * max(abs(s))` and ending with `sigma_min`. At each \n",
    "      step, the function adjusts `s` to minimize the L0-norm by smoothing it using \n",
    "      a Gaussian kernel.\n",
    "    \n",
    "    - The choice of `sigma_min` is crucial: for noiseless cases, a smaller `sigma_min` \n",
    "      yields a sparser solution; for noisy cases, `sigma_min` should be a few times \n",
    "      the standard deviation of the noise in `s`.\n",
    "\n",
    "    - If `A_pinv` is precomputed and passed as an argument, the function becomes \n",
    "      more efficient, especially in scenarios where it is called repeatedly with the \n",
    "      same `A`.\n",
    "\n",
    "      \n",
    "      References:\n",
    "      ----------\n",
    "    - Original authors (MATLAB): Massoud Babaie-Zadeh, Hossein Mohimani, 4 August 2008.\n",
    "    - Web-page: http://ee.sharif.ir/~SLzero\n",
    "\n",
    "    - Ported to python: RosNaviGator https://github.com/RosNaviGator, 2024\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "    if A_pinv is None:\n",
    "        A_pinv = np.linalg.pinv(A)\n",
    "\n",
    "    # Initialize the variables\n",
    "    s = A_pinv @ y\n",
    "    sigma = 2 * max(np.abs(s))\n",
    "\n",
    "    # Define lambda function for delta\n",
    "    OurDelta = lambda s, sigma: s * np.exp(-s**2 / sigma**2)\n",
    " \n",
    "    # Main loop\n",
    "    while sigma > sigma_min:\n",
    "        for i in range(L):\n",
    "            delta = OurDelta(s, sigma)\n",
    "            s = s - mu_0 * delta\n",
    "            s = s - A_pinv @ (A @ s - y)\n",
    "        \n",
    "        if showProgress:\n",
    "            print(f'sigma: {sigma}')\n",
    "\n",
    "        sigma = sigma * sigma_decrease_factor\n",
    "\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script provides functions to calculate the Signal-to-Noise Ratio (SNR) between \n",
    "an original and a reconstructed signal, and to plot these signals together, displaying \n",
    "the SNR. It also includes functionality to save the plotted signals to a specified directory.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def calculate_snr(signal, recovered_signal):\n",
    "    \"\"\"\n",
    "    Calculates the Signal-to-Noise Ratio (SNR) between the original signal and the recovered signal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : numpy.ndarray\n",
    "        The original signal.\n",
    "    recovered_signal : numpy.ndarray\n",
    "        The recovered signal after some processing or recovery algorithm.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    snr : float\n",
    "        The Signal-to-Noise Ratio (SNR) in decibels (dB).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The SNR is calculated as 20 * log10(norm(original_signal) / norm(original_signal - recovered_signal)).\n",
    "    - A higher SNR value indicates a better recovery, with less error relative to the original signal.\n",
    "    \"\"\"\n",
    "    error = recovered_signal - signal\n",
    "    snr = 20 * np.log10(np.linalg.norm(signal) / np.linalg.norm(error))\n",
    "    \n",
    "    return snr\n",
    "\n",
    "\n",
    "\n",
    "def plot_signals(original_signal, reconstructed_signal, snr=None, original_name=\"Original Signal\", \n",
    "                 reconstructed_name=\"Reconstructed Signal\", save_path=None, filename=None):\n",
    "    \"\"\"\n",
    "    Plots the original signal and the reconstructed signal on the same plot with the given names,\n",
    "    displays the Signal-to-Noise Ratio (SNR) in a text box, and saves the plot to a specified directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    original_signal : numpy.ndarray\n",
    "        The original signal to be plotted.\n",
    "    \n",
    "    reconstructed_signal : numpy.ndarray\n",
    "        The reconstructed signal to be plotted.\n",
    "    \n",
    "    original_name : str, optional (default=\"Original Signal\")\n",
    "        The name to display for the original signal in the plot.\n",
    "    \n",
    "    reconstructed_name : str, optional (default=\"Reconstructed Signal\")\n",
    "        The name to display for the reconstructed signal in the plot.\n",
    "    \n",
    "    save_path : str, optional\n",
    "        The directory path where the plot should be saved. If None, the plot will not be saved.\n",
    "    \n",
    "    filename : str, optional\n",
    "        The name of the file to save the plot as. If None and save_path is provided, a default name will be generated.\n",
    "\n",
    "    snr : float, optional (default=None)\n",
    "        The Signal-to-Noise Ratio to display. If None, it will be computed using the original and reconstructed signals.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the signals have the same length\n",
    "    if len(original_signal) != len(reconstructed_signal):\n",
    "        raise ValueError(\"The original signal and the reconstructed signal must have the same length.\")\n",
    "    \n",
    "    # Calculate SNR if not provided\n",
    "    if snr is None:\n",
    "        snr = calculate_snr(original_signal, reconstructed_signal)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(original_signal, label=original_name, color='blue', linewidth=1.5)\n",
    "    plt.plot(reconstructed_signal, label=reconstructed_name, color='red', linestyle='--', linewidth=1.5)\n",
    "    \n",
    "    # Title and labels\n",
    "    plt.title(f\"{original_name} vs {reconstructed_name}\")\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Amplitude')\n",
    "    \n",
    "    # Add a legend\n",
    "    plt.legend()\n",
    "    \n",
    "    # Display SNR in a text box\n",
    "    plt.text(0.05, 0.95, f'SNR: {snr:.2f} dB', transform=plt.gca().transAxes,\n",
    "             fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Grid and show plot\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the plot if a save path is provided\n",
    "    if save_path is not None:\n",
    "        # Ensure the save directory exists\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        # Use provided filename or generate a default one\n",
    "        if filename is None:\n",
    "            filename = f\"{original_name}_vs_{reconstructed_name}.png\"\n",
    "        \n",
    "        # Define the file path to save the plot\n",
    "        file_path = os.path.join(save_path, filename)\n",
    "        plt.savefig(file_path)\n",
    "        print(f\"Plot saved to {file_path}\")\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Orthogonal Matching Pursuit (OMP) algorithm for sparse coding.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def OMP(dictio, sig, max_coeff):\n",
    "    \"\"\"\n",
    "    Orthogonal Matching Pursuit (OMP) algorithm for sparse coding.\n",
    "\n",
    "    This function implements the OMP algorithm, which is used to find the sparse\n",
    "    representation of a signal over a given dictionary.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dictio : numpy.ndarray\n",
    "        The dictionary to use for sparse coding. It should be a matrix of size (n x K), \n",
    "        where n is the signal dimension and K is the number of atoms in the dictionary.\n",
    "        (its columns MUST be normalized).\n",
    "    \n",
    "    sig : numpy.ndarray\n",
    "        The signals to represent using the dictionary. \n",
    "        It should be a matrix of size (n x N), where N is the number of signals.\n",
    "    \n",
    "    max_coeff : int\n",
    "        The maximum number of coefficients to use for representing each signal.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    s : numpy.ndarray\n",
    "        The sparse representation of the signals over the dictionary.\n",
    "        It should be a matrix of size (K x N).\n",
    "    \"\"\"\n",
    "\n",
    "    [n, p] = sig.shape\n",
    "    [_, key] = dictio.shape\n",
    "    s = np.zeros((key, p))\n",
    "    for k in range(p):\n",
    "        x = sig[:, k]\n",
    "        residual = x.copy()\n",
    "        indx = np.array([], dtype=int)\n",
    "        current_atoms = np.empty((n, 0))\n",
    "        norm_x = np.linalg.norm(x)\n",
    "        for j in range(max_coeff):\n",
    "            proj = dictio.T @ residual\n",
    "            pos = np.argmax(np.abs(proj))\n",
    "            indx = np.append(indx, pos)\n",
    "            # Update selected atoms matrix\n",
    "            current_atoms = np.column_stack((current_atoms, dictio[:, pos]))\n",
    "            # Solve least squares problem using QR decomposition for stability\n",
    "            q, r = np.linalg.qr(current_atoms)\n",
    "            a = np.linalg.solve(r, q.T @ x)\n",
    "            residual = x - current_atoms @ a\n",
    "            # Break if norm of residual is suff small (relative to original signal)\n",
    "            if np.linalg.norm(residual) < 1e-6 * norm_x:\n",
    "                break\n",
    "        temp = np.zeros((key,))\n",
    "        temp[indx] = a\n",
    "        s[:, k] = temp\n",
    "\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MOD (Method of Optimal Directions) algorithm for dictionary learning with improved numerical stability.\n",
    "\"\"\"\n",
    "\n",
    "# system imports\n",
    "import os\n",
    "\n",
    "# third party imports\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.linalg import solve\n",
    "\n",
    "\n",
    "\n",
    "def I_findDistanceBetweenDictionaries(original, new):\n",
    "    \"\"\"\n",
    "    Calculates the distance between two dictionaries.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    original : numpy.ndarray\n",
    "        The original dictionary.\n",
    "\n",
    "    new : numpy.ndarray\n",
    "        The new dictionary.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    catchCounter : int\n",
    "        The number of elements that satisfy the condition errorOfElement < 0.01.\n",
    "    totalDistances : float\n",
    "        The sum of all errorOfElement values.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # first: all the columns in the original start with positive values\n",
    "    catchCounter = 0\n",
    "    totalDistances = 0\n",
    "\n",
    "    for i in range(new.shape[1]):\n",
    "        new[:,i] = np.sign(new[0,i]) * new[:,i]\n",
    "\n",
    "    for i in range(original.shape[1]):\n",
    "        d = np.sign(original[0,i]) * original[:,i]\n",
    "        distances = np.sum(new - np.tile(d, (1, new.shape[1])), axis=0)\n",
    "        index = np.argmin(distances)\n",
    "        errorOfElement = 1 - np.abs(new[:,index].T @ d)\n",
    "        totalDistances += errorOfElement\n",
    "        catchCounter += errorOfElement < 0.01\n",
    "\n",
    "    ratio = catchCounter / original.shape[1]\n",
    "    return ratio, totalDistances\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MOD(data, parameters):\n",
    "    \"\"\"\n",
    "    Method of Optimal Directions (MOD) algorithm for dictionary learning .\n",
    "\n",
    "    The MOD algorithm is a method for learning a dictionary for sparse representation of signals.\n",
    "    It iteratively updates the dictionary to best represent the input data with sparse coefficients\n",
    "    using the Orthogonal Matching Pursuit (OMP) algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        An (n x N) matrix containing N signals, each of dimension n.\n",
    "    \n",
    "    parameters : dict\n",
    "        A dictionary containing the parameters for the MOD algorithm:\n",
    "            - K : int\n",
    "                The number of dictionary elements (columns) to train.\n",
    "            \n",
    "            - num_iterations : int\n",
    "                The number of iterations to perform for dictionary learning.\n",
    "            \n",
    "            - initialization_method : str\n",
    "                Method to initialize the dictionary. Options are:\n",
    "                * 'DataElements' - Initializes the dictionary using the first K data signals.\n",
    "                * 'GivenMatrix' - Initializes the dictionary using a provided matrix \n",
    "                  (requires 'initial_dictionary' key).\n",
    "\n",
    "            - initial_dictionary : numpy.ndarray, optional\n",
    "                The initial dictionary matrix to use if 'initialization_method' is \n",
    "                set to 'GivenMatrix'. It should be of size (n x K).\n",
    "\n",
    "            - L : int\n",
    "                The number of non-zero coefficients to use in OMP for sparse\n",
    "                representation of each signal.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dictionary : numpy.ndarray\n",
    "        The trained dictionary of size (n x K), where each column is a dictionary element.\n",
    "\n",
    "    coef_matrix : numpy.ndarray\n",
    "        The coefficient matrix of size (K x N), representing the sparse representation\n",
    "        of the input data using the trained dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the number of signals is smaller than the dictionary size\n",
    "    if data.shape[1] < parameters['K']:\n",
    "        print(\"MOD: number of training signals is smaller than the dictionary size. Returning trivial solution...\")\n",
    "        dictionary = data[:, :data.shape[1]]\n",
    "        coef_matrix = np.eye(data.shape[1])  # Trivial coefficients\n",
    "        return dictionary, coef_matrix\n",
    "\n",
    "    # Initialize dictionary based on the specified method\n",
    "    if parameters['initialization_method'] == 'DataElements':\n",
    "        dictionary = data[:, :parameters['K']]\n",
    "    elif parameters['initialization_method'] == 'GivenMatrix':\n",
    "        if 'initial_dictionary' not in parameters:\n",
    "            raise ValueError(\"initial_dictionary parameter is required when \"\n",
    "                             \"initialization_method is set to 'GivenMatrix'.\")\n",
    "        dictionary = parameters['initial_dictionary']\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid value for initialization_method. Choose 'DataElements' or 'GivenMatrix'.\")\n",
    "\n",
    "    # Convert to float64 for precision\n",
    "    dictionary = dictionary.astype(np.float64)\n",
    "\n",
    "    # Normalize dictionary columns and avoid division by zero\n",
    "    column_norms = np.linalg.norm(dictionary, axis=0)\n",
    "    column_norms[column_norms < 1e-10] = 1  # Prevent division by zero\n",
    "    dictionary /= column_norms\n",
    "\n",
    "    # Ensure positive first elements\n",
    "    dictionary *= np.sign(dictionary[0, :])\n",
    "\n",
    "    prev_dictionary = dictionary.copy()\n",
    "\n",
    "    # Run MOD algorithm\n",
    "    for iter_num in range(parameters['num_iterations']):\n",
    "        # Step 1: Sparse coding using OMP\n",
    "        coef_matrix = OMP(dictionary, data, parameters['L'])\n",
    "\n",
    "        # Step 2: Update the dictionary\n",
    "        regularization_term = 1e-7 * sp.eye(coef_matrix.shape[0])\n",
    "        matrix_a = coef_matrix @ coef_matrix.T + regularization_term.toarray()\n",
    "\n",
    "        # Use solve instead of np.linalg.inv for better numerical stability\n",
    "        dictionary = data @ coef_matrix.T @ solve(\n",
    "            matrix_a, np.eye(matrix_a.shape[0]), assume_a='pos')\n",
    "\n",
    "        # Normalize dictionary columns and avoid division by zero\n",
    "        column_norms = np.linalg.norm(dictionary, axis=0)\n",
    "        column_norms[column_norms < 1e-10] = 1  # Prevent division by zero\n",
    "        dictionary /= column_norms\n",
    "\n",
    "        # Ensure positive first elements\n",
    "        dictionary *= np.sign(dictionary[0, :])\n",
    "\n",
    "        # Convergence check\n",
    "        if np.linalg.norm(dictionary - prev_dictionary) < 1e-5:\n",
    "            print(f\"MOD converged after {iter_num + 1} iterations.\")\n",
    "            break\n",
    "\n",
    "        prev_dictionary = dictionary.copy()\n",
    "\n",
    "    return dictionary, coef_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K-SVD algorithm for dictionary learning and sparse coding using Orthogonal Matching Pursuit (OMP).\n",
    "Includes functions for updating dictionary elements, handling singular value decomposition (SVD)\n",
    "for vectors, and clearing redundant dictionary elements.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "\n",
    "def svds_vector(v):\n",
    "    \"\"\"\n",
    "    Handle SVD for a vector or a 2D matrix with one dimension equal to 1.\n",
    "    \"\"\"\n",
    "    v = np.asarray(v)\n",
    "    \n",
    "    if v.ndim == 1:\n",
    "        v = v.reshape(-1, 1)\n",
    "    elif v.ndim == 2 and (v.shape[0] == 1 or v.shape[1] == 1):\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a vector or a 2D array with one dimension equal to 1.\")\n",
    "    \n",
    "    s = np.linalg.norm(v)\n",
    "    if s > 0:\n",
    "        u = v / s\n",
    "    else:\n",
    "        u = np.zeros_like(v)\n",
    "    \n",
    "    vt = np.array([[1]])\n",
    "\n",
    "    return u, s, vt\n",
    "\n",
    "def I_findBetterDictionaryElement(data, dictionary, j, coeff_matrix, numCoefUsed=1):\n",
    "    \"\"\"\n",
    "    Update the j-th dictionary element.\n",
    "    \"\"\"\n",
    "    relevantDataIndices = np.nonzero(coeff_matrix[j, :])[0]\n",
    "    if relevantDataIndices.size == 0:\n",
    "        errorMat = data - dictionary @ coeff_matrix\n",
    "        errorNormVec = np.sum(errorMat ** 2, axis=0)\n",
    "        i = np.argmax(errorNormVec)\n",
    "        betterDictionaryElement = data[:, i] / np.linalg.norm(data[:, i])\n",
    "        betterDictionaryElement *= np.sign(betterDictionaryElement[0])\n",
    "        coeff_matrix[j, :] = 0\n",
    "        newVectAdded = 1\n",
    "        return betterDictionaryElement, coeff_matrix, newVectAdded\n",
    "    \n",
    "    newVectAdded = 0\n",
    "    tmpCoefMatrix = coeff_matrix[:, relevantDataIndices]\n",
    "    tmpCoefMatrix[j, :] = 0\n",
    "    errors = data[:, relevantDataIndices] - dictionary @ tmpCoefMatrix\n",
    "\n",
    "    if np.min(errors.shape) <= 1:\n",
    "        u, s, vt = svds_vector(errors)\n",
    "        betterDictionaryElement = u\n",
    "        singularValue = s\n",
    "        betaVector = vt\n",
    "    else:\n",
    "        u, s, vt = svds(errors, k=1)\n",
    "        betterDictionaryElement = u[:, 0]\n",
    "        singularValue = s[0]\n",
    "        betaVector = vt[0, :]\n",
    "\n",
    "    coeff_matrix[j, relevantDataIndices] = singularValue * betaVector.T\n",
    "\n",
    "    return betterDictionaryElement, coeff_matrix, newVectAdded\n",
    "\n",
    "def I_clearDictionary(dictionary, coeff_matrix, data):\n",
    "    \"\"\"\n",
    "    Clear or replace redundant dictionary elements.\n",
    "    \"\"\"\n",
    "    T2 = 0.99\n",
    "    T1 = 3\n",
    "    K = dictionary.shape[1]\n",
    "    Er = np.sum((data - dictionary @ coeff_matrix) ** 2, axis=0)\n",
    "    G = dictionary.T @ dictionary\n",
    "    G -= np.diag(np.diag(G))\n",
    "    for jj in range(K):\n",
    "        if np.max(G[jj, :]) > T2 or np.count_nonzero(np.abs(coeff_matrix[jj, :]) > 1e-7) <= T1:\n",
    "            pos = np.argmax(Er)\n",
    "            Er[pos] = 0\n",
    "            dictionary[:, jj] = data[:, pos] / np.linalg.norm(data[:, pos])\n",
    "            G = dictionary.T @ dictionary\n",
    "            G -= np.diag(np.diag(G))\n",
    "    return dictionary\n",
    "\n",
    "def KSVD(data, param):\n",
    "    \"\"\"\n",
    "    K-SVD algorithm for dictionary learning.\n",
    "    \"\"\"\n",
    "    if param['preserve_dc_atom'] > 0:\n",
    "        fixedDictElem = np.zeros((data.shape[0], 1))  \n",
    "        fixedDictElem[:data.shape[0], 0] = 1 / np.sqrt(data.shape[0])\n",
    "    else:\n",
    "        fixedDictElem = np.empty((0, 0))\n",
    "\n",
    "    if data.shape[1] < param['K']:\n",
    "        print('KSVD: number of training data is smaller than the dictionary size. Trivial solution...')\n",
    "        dictionary = data[:, :data.shape[1]]\n",
    "        coef_matrix = np.eye(data.shape[1])\n",
    "        return dictionary, coef_matrix\n",
    "    \n",
    "    dictionary = np.zeros((data.shape[0], param['K']), dtype=np.float64)    \n",
    "    if param['initialization_method'] == 'DataElements':\n",
    "        dictionary[:, :param['K'] - param['preserve_dc_atom']] = \\\n",
    "            data[:, :param['K'] - param['preserve_dc_atom']]\n",
    "    elif param['initialization_method'] == 'GivenMatrix':\n",
    "        dictionary[:, :param['K'] - param['preserve_dc_atom']] = \\\n",
    "            param['initial_dictionary'][:, :param['K'] - param['preserve_dc_atom']]\n",
    "\n",
    "    if param['preserve_dc_atom']:\n",
    "        tmpMat = np.linalg.lstsq(dictionary + 1e-7 * np.eye(dictionary.shape[1]), fixedDictElem, rcond=None)[0]\n",
    "        dictionary -= fixedDictElem @ tmpMat\n",
    "\n",
    "    column_norms = np.sqrt(np.sum(dictionary ** 2, axis=0))\n",
    "    column_norms[column_norms < 1e-10] = 1\n",
    "    dictionary /= column_norms\n",
    "    dictionary *= np.sign(dictionary[0, :])\n",
    "\n",
    "    for iterNum in range(param['num_iterations']):\n",
    "        coef_matrix = OMP(\n",
    "            np.hstack((fixedDictElem, dictionary)) if fixedDictElem.size > 0 else dictionary,\n",
    "            data,\n",
    "            param['L']\n",
    "        )\n",
    "        \n",
    "        rand_perm = np.random.permutation(dictionary.shape[1])\n",
    "        for j in rand_perm:\n",
    "            betterDictElem, coef_matrix, newVectAdded = I_findBetterDictionaryElement(\n",
    "                data,\n",
    "                np.hstack((fixedDictElem, dictionary)) if fixedDictElem.size > 0 else dictionary,\n",
    "                j + fixedDictElem.shape[1],\n",
    "                coef_matrix,\n",
    "                param['L']\n",
    "            )\n",
    "\n",
    "            dictionary[:, j] = betterDictElem.ravel()\n",
    "            if param['preserve_dc_atom']:\n",
    "                tmpCoeff = np.linalg.lstsq(betterDictElem + 1e-7, fixedDictElem, rcond=None)[0]\n",
    "                dictionary[:, j] -= fixedDictElem @ tmpCoeff\n",
    "                dictionary[:, j] /= np.linalg.norm(dictionary[:, j])\n",
    "\n",
    "        dictionary = I_clearDictionary(dictionary, coef_matrix[fixedDictElem.shape[1]:, :], data)\n",
    "\n",
    "    dictionary = np.hstack((fixedDictElem, dictionary)) if fixedDictElem.size > 0 else dictionary\n",
    "    \n",
    "    return dictionary, coef_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_DBBD_matrix(M, N):\n",
    "    \"\"\"\n",
    "    Generates a deterministic Diagonally Blocked Block Diagonal (DBBD) matrix.\n",
    "\n",
    "    A DBBD matrix is a type of block diagonal matrix where each block is a square diagonal matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    M : int\n",
    "        Number of rows in the matrix.\n",
    "    N : int\n",
    "        Number of columns in the matrix. Should be a multiple of M.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A : numpy.ndarray\n",
    "        The generated DBBD matrix of shape (M, N).\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `N` is not a multiple of `M`.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> generate_DBDD_matrix(3, 9)\n",
    "    array([[1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "           [0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
    "           [0., 0., 0., 0., 0., 0., 1., 1., 1.]])\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if N % M != 0:\n",
    "        raise ValueError(\"N should be a multiple of M.\")\n",
    "    \n",
    "    Phi = np.zeros((M, N))\n",
    "    m = N // M\n",
    "    \n",
    "    for i in range(M):\n",
    "        Phi[i, i*m:(i+1)*m] = 1\n",
    "\n",
    "    return Phi\n",
    "\n",
    "\n",
    "def generate_random_matrix(M, N, matrix_type='gaussian'):\n",
    "    \"\"\"\n",
    "    Generates a random matrix based on the specified type.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    M : int\n",
    "        Number of rows in the matrix.\n",
    "    N : int\n",
    "        Number of columns in the matrix.\n",
    "    matrix_type : str, optional (default='gaussian')\n",
    "        The type of random matrix to generate. Options are:\n",
    "        - 'gaussian': A matrix with entries drawn from a normal distribution scaled by 1/M.\n",
    "        - 'scaled_binary': A matrix with binary entries (±0.5), scaled by 1/sqrt(M).\n",
    "        - 'unscaled_binary': A matrix with binary entries (±1), with no scaling.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A : numpy.ndarray\n",
    "        The generated random matrix of shape (M, N).\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `matrix_type` is not one of the supported types.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> generate_random_matrix(2, 3, matrix_type='gaussian')\n",
    "    array([[ 0.01, -0.02,  0.03],\n",
    "           [-0.04,  0.05, -0.06]])\n",
    "\n",
    "    >>> generate_random_matrix(2, 3, matrix_type='scaled_binary')\n",
    "    array([[-0.5,  0. , -0.5],\n",
    "           [ 0.5, -0.5,  0. ]])\n",
    "    \n",
    "    >>> generate_random_matrix(2, 3, matrix_type='unscaled_binary')\n",
    "    array([[ 1., -1.,  1.],\n",
    "           [-1.,  1., -1.]])\n",
    "    \"\"\"\n",
    "    if matrix_type == 'gaussian':\n",
    "        A = ((1/M)**2) * np.random.randn(M, N)\n",
    "\n",
    "    elif matrix_type == 'scaled_binary':\n",
    "        A = np.random.binomial(1, 0.5, size=(M, N)) - 0.5\n",
    "        A = (1/np.sqrt(M)) * A\n",
    "\n",
    "    elif matrix_type == 'unscaled_binary':\n",
    "        A = np.random.binomial(1, 0.5, size=(M, N)) * 2 - 1\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported matrix type. Choose either 'gaussian', 'scaled_binary', or 'unscaled_binary'.\")\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIGHER LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".namlVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
